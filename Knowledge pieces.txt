
### R ###
read.csv(file.choose())

#Feature engineering
rowSums()

#Explorative analysis
facet_wrap(~vendor_id)

#Format conversion
wday = fct_relevel(wday, c("Mon", "Tues", "Wed", "Thurs", "Fri", "Sat", "Sun"))
as.Date()
paste() #factor to string


###Python###
#import data
pd.read_csv()

#Check the data
.head(20)
.info()
.dtypes
.columns
.index

#Count NAs
.count() #count of records excluding missing
.isnull().sum() #count of missing records
.isnull().count() #count of records including missing
.isnull().sum().sort_values(ascending = False)

#Fix NAs
.fillna()
.dropna()

#Stat summary
.describe()
.nlargest()
.max()
.mean()
.sum()
.std()

#Feature engineering
pd.concat()
pd.merge(df1,df2,on = "xxx", how = "outer")
pd.cut()
pd.qcut()
.replace(['a','b','c'] = [1,2,3])
.loc([condition],column) = xxx
.drop(column_list, axis = 1)
.groupby().describe()

#Format conversion
.astype()
.map()

#Explorative analysis
.plot.scatter()
.corr()
sns.heatmap(.corr(),)
sns.boxplot()
sns.pairplot()
.pivot(index = , columns = , values = )
.pivot_table(index = , columns = , aggfunc =, margins = True )

#Model preparation
pd.get_dummies()

#Model training
  # Some useful parameters which will come in handy later on
ntrain = train.shape[0]
ntest = test.shape[0]
SEED = 0 # for reproducibility
NFOLDS = 5 # set folds for out-of-fold prediction
kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)

.fit(X,Y)
.train(X,Y)
.predict(X)
.feature_importances(x_train,y_train)

# Random Forest parameters
rf_params = {
    'n_jobs': -1,
    'n_estimators': 500,
     'warm_start': True, 
     #'max_features': 0.2,
    'max_depth': 6,
    'min_samples_leaf': 2,
    'max_features' : 'sqrt',
    'verbose': 0
}

# Extra Trees Parameters
et_params = {
    'n_jobs': -1,
    'n_estimators':500,
    #'max_features': 0.5,
    'max_depth': 8,
    'min_samples_leaf': 2,
    'verbose': 0
}

# AdaBoost parameters
ada_params = {
    'n_estimators': 500,
    'learning_rate' : 0.75
}

# Gradient Boosting parameters
gb_params = {
    'n_estimators': 500,
     #'max_features': 0.2,
    'max_depth': 5,
    'min_samples_leaf': 2,
    'verbose': 0
}

# Support Vector Classifier parameters 
svc_params = {
    'kernel' : 'linear',
    'C' : 0.025
    }
