
### R ###
read.csv(file.choose())

#Feature engineering
rowSums()
substr()

#Explorative analysis
facet_wrap(~vendor_id)

#Format conversion
wday = fct_relevel(wday, c("Mon", "Tues", "Wed", "Thurs", "Fri", "Sat", "Sun"))
as.Date()
as.matrix()
paste() #factor to string


###Python Pandas###
#import data
pd.read_csv()

#Check the data
.head(20)
.info()
.dtypes
.columns
.index

#Count NAs
.count() #count of records excluding missing
.isnull().sum() #count of missing records
.isnull().count() #count of records including missing
.isnull().sum().sort_values(ascending = False)

#Fix NAs
.fillna()
.dropna()

#Stat summary
.describe()
.nlargest()
.max()
.mean()
.sum()
.std()

#Feature engineering
pd.concat()
pd.merge(df1,df2,on = "xxx", how = "outer")
pd.cut()
pd.qcut()
pd.melt(df, id_vars = [])
.replace(['a','b','c'] = [1,2,3])
.loc([condition],column) = xxx
.drop(column_list, axis = 1)
.groupby().describe()

#Format conversion
.astype()
.map()

#Explorative analysis
.plot.scatter()
.corr()
sns.heatmap(.corr(),)
sns.boxplot()
sns.pairplot()
.pivot(index = , columns = , values = )
.pivot_table(index = , columns = , aggfunc =, margins = True )
pd.crosstab(df.var1, df.var2, margins = True)

#Model preparation
pd.get_dummies()

#Model training
  # Some useful parameters which will come in handy later on
ntrain = train.shape[0]
ntest = test.shape[0]
SEED = 0 # for reproducibility
NFOLDS = 5 # set folds for out-of-fold prediction
kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)

.fit(X,Y)
.train(X,Y)
.predict(X)
.feature_importances(x_train,y_train)

# Random Forest parameters
rf_params = {
    'n_jobs': -1,
    'n_estimators': 500,
     'warm_start': True, 
     #'max_features': 0.2,
    'max_depth': 6,
    'min_samples_leaf': 2,
    'max_features' : 'sqrt',
    'verbose': 0
}

# Extra Trees Parameters
et_params = {
    'n_jobs': -1,
    'n_estimators':500,
    #'max_features': 0.5,
    'max_depth': 8,
    'min_samples_leaf': 2,
    'verbose': 0
}

# AdaBoost parameters
ada_params = {
    'n_estimators': 500,
    'learning_rate' : 0.75
}

# Gradient Boosting parameters
gb_params = {
    'n_estimators': 500,
     #'max_features': 0.2,
    'max_depth': 5,
    'min_samples_leaf': 2,
    'verbose': 0
}

# Support Vector Classifier parameters 
svc_params = {
    'kernel' : 'linear',
    'C' : 0.025
    }

###Python Numpy###

a = np.arrary([5,6,7])              #Create a one dim arrary
a = np.array([[1,2],[3,4],[5,6]])   #Create a two dim array
a = np.arange(5)                    #Create a series of numbers
a = np.arange(1,5,2)                #Create a series of numbers by specifying start, stop, and step
a = np.linspace(1,5,10)             #Create a series of numbers by specifying start, stop, and # of numbers in between


a.ndim          #print the dim
a.itemsize      #item size
a.dtype         #type
a.size          #size
a.shape         #row by col
a.reshape(2,3)  #reshape to interested dimensions
a.ravel()       #flatten a array

a.min()
a.max()
a.sum()
a.sum(axis = 0) #col sum
a.sum(axis = 1) #row sum

np.sqrt(a)
np.std(a) 

a+b
a*b
a/b
a.dot(b)  #matrix multiplication

#index and slice
a[0:2]
a[-1]

#Stack
np.vstack((a,b))
np.hstach((a,b))

#Split
np.vsplit(a,2)
np.hsplit(a,3)


###Python Programming###
Alist.append()
Alist.insert()      #e.g. Alist.insert(1,'butter')
len(Alist)
"astring" in Alist  #look up item in a list
